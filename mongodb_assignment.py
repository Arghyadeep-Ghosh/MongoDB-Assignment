# -*- coding: utf-8 -*-
"""MongoDB_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19IVN4rDQb-wzRxeuRRSTcM-hpiPEBliH
"""

# Q1)  What are the key differences between SQL and NoSQL databases?

# Ans)
# Key Differences Between SQL and NoSQL Databases:

# 1. Structure:
#    - SQL databases are structured and use tables with predefined schemas.
#    - NoSQL databases are unstructured or semi-structured and use collections, key-value pairs, documents, or graphs.

# 2. Schema:
#    - SQL databases have a fixed schema (strict structure).
#    - NoSQL databases have a flexible schema (dynamic structure).

# 3. Scalability:
#    - SQL databases scale vertically (adding more power to a single server).
#    - NoSQL databases scale horizontally (adding more servers to distribute the load).

# 4. Data Storage Model:
#    - SQL databases store data in relational tables.
#    - NoSQL databases store data in various models like document-based (MongoDB), key-value stores (Redis), column-family stores (Cassandra), or graph-based (Neo4j).

# 5. Query Language:
#    - SQL databases use Structured Query Language (SQL) for querying.
#    - NoSQL databases use different query methods, like JSON-based queries in MongoDB.

# 6. Transactions:
#    - SQL databases support ACID (Atomicity, Consistency, Isolation, Durability) transactions.
#    - NoSQL databases often follow the BASE (Basically Available, Soft state, Eventually consistent) model for flexibility.

# 7. Use Cases:
#    - SQL is suitable for applications that require structured data, consistency, and complex queries (e.g., banking, ERP).
#    - NoSQL is ideal for handling large volumes of unstructured or semi-structured data with high scalability (e.g., real-time applications, big data, IoT).

#Q2)  What makes MongoDB a good choice for modern applications?

# Ans)
# What Makes MongoDB a Good Choice for Modern Applications?

# 1. **Flexible Schema:**
#    - MongoDB is a NoSQL database that uses a document-based structure (BSON format, similar to JSON).
#    - It allows dynamic and flexible schemas, making it easy to store different types of data without predefined structures.

# 2. **Scalability:**
#    - MongoDB supports horizontal scaling using sharding, which distributes data across multiple servers.
#    - This ensures high performance and allows handling of large volumes of data.

# 3. **High Performance:**
#    - It provides fast read and write operations by using indexing and in-memory computing.
#    - Its document model reduces the need for complex joins, improving query performance.

# 4. **Support for Big Data and Real-Time Applications:**
#    - MongoDB is optimized for handling large-scale data and is widely used in big data, IoT, AI, and machine learning applications.
#    - It supports real-time analytics and data processing.

# 5. **Easy Integration with Modern Technologies:**
#    - MongoDB seamlessly integrates with cloud platforms, microservices architecture, and modern development frameworks.
#    - It supports various programming languages like Python, JavaScript, Java, and Node.js.

# 6. **Built-in Replication and High Availability:**
#    - MongoDB provides automatic replication through replica sets, ensuring data redundancy and fault tolerance.
#    - If a primary server fails, a secondary server automatically takes over.

# 7. **Powerful Querying and Aggregation:**
#    - It supports rich queries, indexing, and powerful aggregation frameworks to process and analyze data efficiently.
#    - Features like geospatial queries and text search enhance its capabilities.

# 8. **Flexible Deployment Options:**
#    - MongoDB can be deployed on-premises, in the cloud (MongoDB Atlas), or in hybrid environments.
#    - Cloud-based solutions offer automatic scaling, backups, and security features.

# 9. **Schema Evolution:**
#    - Unlike relational databases, MongoDB allows easy schema evolution without migration issues.
#    - This makes it suitable for applications that require frequent updates and changes.

# 10. **Open Source and Community Support:**
#    - MongoDB is open-source with a large developer community.
#    - It has extensive documentation, making it easy for developers to learn and implement.

# Q3)  Explain the concept of collections in MongoDB.

# Ans)
# Concept of Collections in MongoDB:

# 1. **Definition:**
#    - A collection in MongoDB is similar to a table in SQL databases.
#    - It is a group of documents (records) that share a common purpose but can have different structures.

# 2. **Flexible Schema:**
#    - Unlike tables in relational databases, collections in MongoDB do not require a fixed schema.
#    - Each document within a collection can have different fields and data types.

# 3. **Storage of Documents:**
#    - Collections store data in BSON (Binary JSON) format.
#    - Each document in a collection is uniquely identified by an `_id` field.

# 4. **Example of a Collection in MongoDB:**
#    - A collection named `students` may contain the following documents:
#      ```
#      { "_id": 1, "name": "Alice", "age": 20, "course": "Computer Science" }
#      { "_id": 2, "name": "Bob", "age": 22, "course": "Mathematics", "grade": "A" }
#      ```
#    - Notice that the second document has an additional field (`grade`), which is allowed due to the flexible schema.

# 5. **Automatic Collection Creation:**
#    - In MongoDB, a collection is automatically created when a document is inserted if it does not already exist.
#    - Example:
#      ```python
#      db.students.insert_one({"name": "Alice", "age": 20, "course": "Computer Science"})
#      ```
#      - If the `students` collection does not exist, MongoDB will create it.

# 6. **Types of Collections:**
#    - **Regular Collections:** Standard collections that store documents.
#    - **Capped Collections:** Fixed-size collections that work as a circular buffer.
#    - **Time-Series Collections:** Optimized for storing time-based data.
#    - **Views:** Read-only collections created from aggregation queries.

# 7. **Advantages of Collections:**
#    - Flexible document structure allows storing diverse data types.
#    - Efficient indexing for faster queries.
#    - Supports high-speed data retrieval and updates.

# 8. **Comparison with SQL Tables:**
#    | SQL Table       | MongoDB Collection |
#    |---------------|------------------|
#    | Row          | Document         |
#    | Column       | Field            |
#    | Schema-based | Schema-less      |
#    | Fixed schema | Dynamic structure |

# Q4) How does MongoDB ensure high availability using replication?

# Ans)
# How Does MongoDB Ensure High Availability Using Replication?

# 1. **Replication in MongoDB:**
#    - Replication in MongoDB is achieved using **Replica Sets**, which provide redundancy and high availability.
#    - A replica set consists of multiple MongoDB instances (nodes) that maintain copies of the same data.

# 2. **Replica Set Components:**
#    - **Primary Node:** Handles all read and write operations.
#    - **Secondary Nodes:** Maintain copies of the primary node’s data and can take over if the primary fails.
#    - **Arbiter (Optional):** Participates in elections but does not store data.

# 3. **How Replication Works:**
#    - The primary node accepts write operations.
#    - Secondary nodes replicate data from the primary asynchronously.
#    - If the primary node fails, an automatic election occurs, and one of the secondary nodes is promoted to primary.

# 4. **Automatic Failover:**
#    - If the primary node goes down, MongoDB automatically elects a new primary from the secondaries.
#    - This ensures continuous database availability without manual intervention.

# 5. **Read Scalability:**
#    - Secondary nodes can serve read queries to distribute the load.
#    - Applications can be configured to read from secondaries in read-heavy environments.

# 6. **Example of a Replica Set Setup (Command in MongoDB Shell):**
#    ```js
#    rs.initiate({
#      _id: "myReplicaSet",
#      members: [
#        { _id: 0, host: "server1:27017" },
#        { _id: 1, host: "server2:27017" },
#        { _id: 2, host: "server3:27017" }
#      ]
#    })
#    ```
#    - This command initializes a replica set with three nodes.

# 7. **Replication Benefits:**
#    - Provides high availability by ensuring data is always accessible.
#    - Enables data redundancy to prevent data loss.
#    - Supports automatic recovery and failover.
#    - Allows horizontal scaling of read operations.

# 8. **Replica Set Election Process:**
#    - When a primary node fails, the secondary nodes hold an election to choose a new primary.
#    - The node with the highest priority and up-to-date data is elected.
#    - Clients automatically reconnect to the new primary.

# 9. **Write Concern and Data Consistency:**
#    - MongoDB allows configuring write concern to ensure data is replicated before confirming a write.
#    - Example:
#      ```python
#      db.collection.insert_one({"name": "Alice"}, write_concern={"w": 2})
#      ```
#      - This ensures the write is acknowledged by at least two replica set members.

# 10. **Use Cases for MongoDB Replication:**
#    - Disaster recovery to prevent data loss.
#    - Load balancing by distributing reads across secondary nodes.
#    - High availability in production environments.

# Summary:
# - MongoDB ensures high availability through **Replica Sets**.
# - If the primary node fails, a **new primary is elected automatically**.
# - Secondary nodes replicate data, ensuring **redundancy and fault tolerance**.
# - This allows **continuous database access and disaster recovery**.

# Q5) What are the main benefits of MongoDB Atlas?

# Ans)
# Main Benefits of MongoDB Atlas

# 1. **Fully Managed Service:** No need for manual database setup, maintenance, or updates.
# 2. **Global Cloud Deployment:** Available on AWS, Google Cloud, and Azure.
# 3. **Automatic Scaling:** Scales vertically and horizontally based on workload.
# 4. **High Availability:** Uses replica sets for automatic failover and minimal downtime.
# 5. **Strong Security:** End-to-end encryption, authentication, and compliance with GDPR, HIPAA, etc.
# 6. **Automated Backups:** Supports continuous and scheduled backups with point-in-time recovery.
# 7. **Performance Monitoring:** Provides real-time insights and query optimization tools.
# 8. **Easy Integration:** Supports multiple programming languages and modern applications.
# 9. **Flexible Pricing:** Pay-as-you-go model with a free-tier option.
# 10. **Multi-Cloud Support:** Deploy across multiple cloud providers or hybrid environments.

# Summary:
# - MongoDB Atlas is a **fully managed, scalable, and secure cloud database**.
# - It ensures **high availability, security, and automatic scaling** for modern applications.

# Q6) What is the role of indexes in MongoDB, and how do they improve performance?

# Ans)
# Role of Indexes in MongoDB and How They Improve Performance

# 1. **What are Indexes?**
#    - Indexes in MongoDB are **data structures** that improve the efficiency of queries.
#    - They store a small portion of the collection’s data in a way that allows fast lookups.

# 2. **How Indexes Improve Performance:**
#    - **Faster Query Execution:** Without an index, MongoDB performs a **collection scan**, checking every document.
#    - **Reduces CPU and Memory Usage:** Queries run efficiently by avoiding unnecessary document scans.
#    - **Optimized Sorting:** Indexes speed up **sort operations** on large datasets.
#    - **Efficient Data Retrieval:** Used in **filtering, searching, and aggregation**.

# 3. **Types of Indexes in MongoDB:**
#    - **Single Field Index:** Created on one field to speed up specific queries.
#    - **Compound Index:** Includes multiple fields for optimized multi-criteria searches.
#    - **Multikey Index:** Used for **array fields** to improve search performance.
#    - **Text Index:** Supports **full-text search** in string-based fields.
#    - **Hashed Index:** Helps distribute data evenly across shards in **sharded clusters**.

# 4. **Creating an Index in MongoDB:**
#    ```python
#    db.collection.create_index([("name", 1)])  # Creates an index on the 'name' field in ascending order
#    ```
#    - The `1` indicates **ascending order**, while `-1` would mean **descending order**.

# 5. **Checking Existing Indexes:**
#    ```python
#    db.collection.list_indexes()
#    ```

# 6. **Removing an Index:**
#    ```python
#    db.collection.drop_index("name_1")
#    ```

# 7. **When to Use Indexes:**
#    - When performing **frequent searches on specific fields**.
#    - When using **sorting or filtering** in large datasets.
#    - When working with **range queries or text searches**.

# 8. **Drawbacks of Indexes:**
#    - **Consumes Additional Storage**: Indexes take up space in memory.
#    - **Slows Down Write Operations**: Inserting or updating documents requires updating the index.

# Summary:
# - **Indexes make queries faster by reducing the number of scanned documents.**
# - **They improve sorting, searching, and filtering efficiency.**
# - **Proper index usage enhances database performance, but excessive indexing may impact write speed.**

# Q7) Describe the stages of the MongoDB aggregation pipeline.

# Ans)
# Stages of the MongoDB Aggregation Pipeline

# 1. **What is the Aggregation Pipeline?**
#    - The aggregation pipeline is a **framework** in MongoDB used to process and analyze data in multiple stages.
#    - Each stage transforms the documents and passes the results to the next stage.

# 2. **Main Stages in the Aggregation Pipeline:**

#    1. **$match** (Filtering Data)
#       - Filters documents based on a condition, similar to the `find()` query.
#       ```python
#       db.collection.aggregate([{"$match": {"category": "Electronics"}}])
#       ```

#    2. **$group** (Grouping Data)
#       - Groups documents based on a field and performs aggregate functions like sum, count, average, etc.
#       ```python
#       db.collection.aggregate([
#           {"$group": {"_id": "$category", "total_price": {"$sum": "$price"}}}
#       ])
#       ```

#    3. **$project** (Reshaping Documents)
#       - Specifies which fields to include or exclude and allows creating computed fields.
#       ```python
#       db.collection.aggregate([
#           {"$project": {"name": 1, "price": 1, "discounted_price": {"$multiply": ["$price", 0.9]}}}
#       ])
#       ```

#    4. **$sort** (Sorting Results)
#       - Sorts documents in ascending (1) or descending (-1) order.
#       ```python
#       db.collection.aggregate([{"$sort": {"price": -1}}])
#       ```

#    5. **$limit** (Limiting Results)
#       - Restricts the number of documents returned.
#       ```python
#       db.collection.aggregate([{"$limit": 5}])
#       ```

#    6. **$skip** (Skipping Documents)
#       - Skips a specified number of documents before returning results.
#       ```python
#       db.collection.aggregate([{"$skip": 3}])
#       ```

#    7. **$unwind** (Deconstructing Arrays)
#       - Breaks an array field into separate documents for further processing.
#       ```python
#       db.collection.aggregate([{"$unwind": "$tags"}])
#       ```

#    8. **$lookup** (Joining Collections)
#       - Performs a **left outer join** to merge data from another collection.
#       ```python
#       db.orders.aggregate([
#           {"$lookup": {
#               "from": "customers",
#               "localField": "customer_id",
#               "foreignField": "_id",
#               "as": "customer_info"
#           }}
#       ])
#       ```

#    9. **$out** (Storing Aggregation Results)
#       - Saves the output of aggregation into a new collection.
#       ```python
#       db.collection.aggregate([{"$match": {"price": {"$gt": 1000}}}, {"$out": "expensive_products"}])
#       ```

# 3. **Combining Multiple Stages:**
#    - Stages are used together to perform advanced data transformations.
#    ```python
#    db.collection.aggregate([
#        {"$match": {"category": "Electronics"}},
#        {"$group": {"_id": "$brand", "average_price": {"$avg": "$price"}}},
#        {"$sort": {"average_price": -1}},
#        {"$limit": 5}
#    ])
#    ```

# Summary:
# - **Aggregation pipeline processes data in stages.**
# - **Each stage refines, transforms, and analyzes the data.**
# - **It is used for filtering, grouping, sorting, joining, and computing results efficiently.**

# Q8)  What is sharding in MongoDB? How does it differ from replication?

# Ans)
# Sharding in MongoDB and Its Difference from Replication

# 1. **What is Sharding?**
#    - Sharding is the process of **splitting large datasets** across multiple servers to ensure better performance.
#    - It allows **horizontal scaling**, meaning data is distributed across multiple machines.
#    - MongoDB uses **shard keys** to determine how data is divided among shards.

# 2. **How Sharding Works:**
#    - **Shards**: The actual servers where data is stored.
#    - **Config Servers**: Store metadata and manage the cluster.
#    - **Mongos Router**: Acts as a query router, directing requests to the appropriate shard.

# 3. **Example of Creating a Sharded Collection:**
#    ```python
#    sh.enableSharding("myDatabase")  # Enable sharding for the database
#    db.adminCommand({"shardCollection": "myDatabase.myCollection", "key": {"user_id": 1}})
#    ```
#    - The **user_id** field is used as the **shard key** to distribute data.

# 4. **Benefits of Sharding:**
#    - Handles **large volumes of data** by distributing it across multiple nodes.
#    - Improves **query performance** by reducing the number of documents per node.
#    - Provides **high availability** when combined with replication.

# 5. **Difference Between Sharding and Replication:**
# | Feature        | Sharding | Replication |
# |--------------|----------|------------|
# | **Purpose** | Distributes data across multiple nodes | Copies the same data across multiple nodes |
# | **Scaling Type** | Horizontal Scaling | Vertical Scaling |
# | **Data Storage** | Different shards store different data | All nodes have the same data |
# | **Failure Handling** | If one shard fails, only part of the data is lost | Provides automatic failover if a node fails |
# | **Performance** | Improves write performance by distributing load | Improves read performance by allowing multiple copies |

# Summary:
# - **Sharding** helps with horizontal scaling by distributing data.
# - **Replication** ensures high availability by creating multiple copies.
# - **A combination of both** provides a robust and scalable MongoDB deployment.

# Q9) What is PyMongo, and why is it used?

# Ans)
# What is PyMongo and Why is it Used?

# 1. **What is PyMongo?**
#    - PyMongo is the **official Python driver** for MongoDB.
#    - It allows Python applications to connect to, query, and manipulate MongoDB databases.

# 2. **Why is PyMongo Used?**
#    - **Database Connectivity**: Helps Python programs interact with MongoDB.
#    - **CRUD Operations**: Supports Create, Read, Update, and Delete operations.
#    - **Aggregation Support**: Allows data analysis using aggregation pipelines.
#    - **Indexing & Performance Optimization**: Helps optimize queries with indexes.
#    - **Scalability**: Works well with MongoDB’s replication and sharding for high availability.

# 3. **Installing PyMongo:**
#    - To install PyMongo, run the following command:
#    ```python
#    !pip install pymongo
#    ```

# 4. **Connecting to MongoDB using PyMongo:**
#    ```python
#    from pymongo import MongoClient

#    # Connect to a local MongoDB instance
#    client = MongoClient("mongodb://localhost:27017/")

#    # Create or access a database
#    db = client["mydatabase"]

#    # Create or access a collection
#    collection = db["mycollection"]

#    # Insert a document
#    collection.insert_one({"name": "Alice", "age": 25})
#    print("Document inserted successfully")
#    ```

# 5. **Performing Basic Queries:**
#    ```python
#    # Fetch all documents
#    for doc in collection.find():
#        print(doc)
#    ```

# Summary:
# - **PyMongo is a Python library for MongoDB.**
# - **It provides an easy-to-use interface for database operations.**
# - **Used for building scalable applications with MongoDB in Python.**

# Q10) What are the ACID properties in the context of MongoDB transactions?

# Ans)
# ACID Properties in the Context of MongoDB Transactions

# 1. **What are ACID Properties?**
#    - ACID stands for **Atomicity, Consistency, Isolation, and Durability**.
#    - These properties ensure **reliable database transactions**.

# 2. **How MongoDB Supports ACID Transactions:**
#    - Starting from **MongoDB 4.0**, multi-document transactions are supported.
#    - Transactions help maintain **data integrity** across multiple operations.

# 3. **ACID Properties Explained in MongoDB:**

#    1. **Atomicity (A)**
#       - A transaction is **all or nothing**.
#       - If one operation fails, the entire transaction is rolled back.
#       ```python
#       session = client.start_session()
#       session.start_transaction()
#       db.collection.insert_one({"name": "Alice", "balance": 100}, session=session)
#       session.abort_transaction()  # If something goes wrong, rollback happens
#       ```

#    2. **Consistency (C)**
#       - The database remains in a **valid state** before and after a transaction.
#       - Enforced using **schema validation** and **constraints**.
#       ```python
#       db.create_collection("users", validator={"$jsonSchema": {"bsonType": "object", "required": ["name", "age"]}})
#       ```

#    3. **Isolation (I)**
#       - Transactions run **independently** and do not interfere with each other.
#       - Uses **snapshot isolation** to ensure a transaction sees a consistent state of the data.
#       ```python
#       with client.start_session() as session:
#           with session.start_transaction():
#               db.collection.update_one({"name": "Alice"}, {"$inc": {"balance": -50}}, session=session)
#               db.collection.update_one({"name": "Bob"}, {"$inc": {"balance": 50}}, session=session)
#       ```

#    4. **Durability (D)**
#       - Once committed, data is **permanently saved** even in case of a failure.
#       - MongoDB writes data to disk using **journaling**.
#       ```python
#       db.adminCommand({"getParameter": 1, "storageEngine": 1})  # Check journaling settings
#       ```

# 4. **Example of an ACID Transaction in MongoDB:**
#    ```python
#    with client.start_session() as session:
#        with session.start_transaction():
#            db.accounts.update_one({"account": "A"}, {"$inc": {"balance": -100}}, session=session)
#            db.accounts.update_one({"account": "B"}, {"$inc": {"balance": 100}}, session=session)
#    print("Transaction committed successfully")
#    ```

# Summary:
# - **MongoDB transactions follow ACID properties** to ensure reliable and safe operations.
# - **Multi-document transactions** provide **Atomicity**.
# - **Schema validation** helps maintain **Consistency**.
# - **Snapshot isolation** ensures **Isolation**.
# - **Journaling and write concerns** guarantee **Durability**.

# Q11) What is the purpose of MongoDB’s explain() function?

# Ans)
# Purpose of MongoDB's explain() Function

# 1. **What is the explain() Function?**
#    - The `explain()` function in MongoDB helps analyze how a query is executed.
#    - It provides **detailed insights** into query execution, including:
#      - Index usage
#      - Execution time
#      - Number of documents scanned

# 2. **Why is explain() Used?**
#    - To **optimize queries** by checking if indexes are being used.
#    - To **analyze performance** by identifying slow queries.
#    - To **debug and tune queries** for better efficiency.

# 3. **Using explain() in MongoDB:**
#    ```python
#    from pymongo import MongoClient

#    # Connect to MongoDB
#    client = MongoClient("mongodb://localhost:27017/")
#    db = client["mydatabase"]
#    collection = db["mycollection"]

#    # Insert sample data
#    collection.insert_many([
#        {"name": "Alice", "age": 25},
#        {"name": "Bob", "age": 30},
#        {"name": "Charlie", "age": 35}
#    ])

#    # Run explain() on a query
#    explanation = collection.find({"age": 30}).explain()
#    print(explanation)
#    ```

# 4. **Types of explain() Modes:**
#    - `"queryPlanner"`: Shows the query plan before execution.
#    - `"executionStats"`: Shows execution time and scanned documents.
#    - `"allPlansExecution"`: Shows execution details for all query plans.

#    ```python
#    explanation = collection.find({"age": 30}).explain("executionStats")
#    print(explanation)
#    ```

# 5. **Optimizing Queries Using explain():**
#    - If `explain()` shows **COLLSCAN** (collection scan), an **index** should be created:
#    ```python
#    collection.create_index([("age", 1)])
#    ```

# Summary:
# - **`explain()` helps analyze query execution plans.**
# - **Used for debugging, optimizing, and improving performance.**
# - **Different modes provide varying levels of details.**

# Q12) How does MongoDB handle schema validation?

# Ans)
# MongoDB handles schema validation using the JSON Schema standard.
# It allows defining validation rules when creating a collection.

# Schema validation is applied using the `$jsonSchema` operator.
# This ensures that documents inserted into the collection follow a predefined structure.

# Validation levels:
# 1. `strict` - Rejects documents that do not match the schema.
# 2. `moderate` - Allows documents that do not match the schema but applies validation to inserts and updates.

# Validation actions:
# 1. `error` - Rejects invalid documents.
# 2. `warn` - Accepts invalid documents but logs a warning.

# Example of schema validation:
# {
#   "bsonType": "object",
#   "required": ["name", "age"],
#   "properties": {
#     "name": { "bsonType": "string", "description": "must be a string" },
#     "age": { "bsonType": "int", "minimum": 18, "description": "must be an integer and at least 18" }
#   }
# }

# This schema ensures that documents contain a "name" as a string and "age" as an integer (18 or older).
# Schema validation helps maintain data consistency in MongoDB.

# Q13) What is the difference between a primary and a secondary node in a replica set?

# Ans)
# In MongoDB, a replica set is a group of MongoDB servers that maintain the same dataset for redundancy and high availability.

# A replica set consists of:
# 1. **Primary Node** - Handles all write and read operations (by default).
# 2. **Secondary Node(s)** - Maintain copies of the primary’s data and replicate changes.

# **Differences between Primary and Secondary Nodes:**

# 1. **Role in Data Operations**
#    - Primary: Accepts all write operations.
#    - Secondary: Replicates data from the primary but does not accept direct writes.

# 2. **Replication Process**
#    - Primary: Applies changes directly to the dataset.
#    - Secondary: Uses the oplog (operation log) to replicate changes from the primary.

# 3. **Failover Mechanism**
#    - If the primary node fails, a new primary is elected from the secondaries automatically.

# 4. **Read Operations**
#    - By default, clients read from the primary.
#    - Secondary nodes can be used for read operations if read preferences allow it.

# 5. **Write Concern & Data Consistency**
#    - Writes to the primary are acknowledged immediately.
#    - Secondary nodes may have a slight replication delay.

# **Example Setup:**
# - Primary: `mongodb://primary_node:27017`
# - Secondary: `mongodb://secondary_node_1:27017`, `mongodb://secondary_node_2:27017`
# - Clients usually connect using a connection string that includes all nodes for failover.

# **Conclusion:**
# - The primary node is responsible for handling writes, while secondary nodes ensure data redundancy and fault tolerance.
# - Replica sets provide automatic failover, improving MongoDB’s availability.

# Q14)  What security mechanisms does MongoDB provide for data protection?

# Ans)
# MongoDB provides several security mechanisms to protect data from unauthorized access, breaches, and threats.

# **1. Authentication**
#    - Ensures that only authorized users can access the database.
#    - Supports various authentication mechanisms, such as:
#      - SCRAM (Salted Challenge Response Authentication Mechanism) - Default method.
#      - x.509 Certificates - Uses SSL/TLS certificates for authentication.
#      - LDAP and Kerberos - Integrates with enterprise authentication systems.

# **2. Authorization (Role-Based Access Control - RBAC)**
#    - Users are assigned roles that define their database permissions.
#    - Common roles include:
#      - `read`: Can only read data.
#      - `readWrite`: Can read and write data.
#      - `dbAdmin`: Can manage database settings.
#      - `root`: Full administrative access.

# **3. Encryption**
#    - **Data Encryption in Transit**:
#      - Uses TLS/SSL to secure data transferred between clients and servers.
#    - **Data Encryption at Rest**:
#      - MongoDB Enterprise supports AES-256 encryption to protect stored data.
#    - **Field-Level Encryption**:
#      - Encrypts specific fields in a document, ensuring sensitive information remains protected even from database administrators.

# **4. Network Security**
#    - IP Whitelisting: Allows only trusted IPs to access the database.
#    - Firewall Rules: Restricts access to MongoDB instances based on network policies.
#    - VPC Peering: Provides secure network communication between MongoDB and other cloud resources.

# **5. Auditing**
#    - MongoDB Enterprise provides audit logs to track database access and modifications.
#    - Helps in monitoring suspicious activities and meeting compliance requirements.

# **6. Automatic Security Updates**
#    - MongoDB regularly releases security patches to address vulnerabilities.
#    - Users should keep MongoDB updated to ensure protection against new threats.

# **Conclusion**
# - MongoDB ensures data protection through authentication, authorization, encryption, and network security.
# - Organizations can enhance security by implementing best practices such as using strong passwords, enabling TLS, and monitoring logs.

# Q15) Explain the concept of embedded documents and when they should be used.

# Ans)
# **Embedded Documents in MongoDB**
# ---------------------------------
# - Embedded documents (also known as nested documents) allow storing related data within a single document.
# - Instead of creating separate collections and using references (like foreign keys in relational databases),
#   MongoDB enables storing structured data within a single JSON-like document.

# **Example of an Embedded Document:**
'''user = {
    "name": "Arghyadeep",
    "email": "arghyadeep@example.com",
    "address": {
        "street": "123 Main St",
        "city": "Kolkata",
        "zip": "700001"
    }
} '''
# - Here, the `address` field is an embedded document inside the `user` document.
# - This avoids the need for a separate `addresses` collection.

# **When to Use Embedded Documents:**
# -----------------------------------
# 1. **One-to-Few Relationships**:
#    - When a document has a small, fixed set of related data.
#    - Example: A user profile with a home and office address.

# 2. **Data That is Always Accessed Together**:
#    - If the embedded data is frequently queried along with the main document.
#    - Example: A blog post with embedded comments, if comments are usually displayed with the post.

# 3. **Improved Read Performance**:
#    - Since all related data is stored together, a single query retrieves everything at once.
#    - Reduces the need for expensive JOIN operations.

# **When Not to Use Embedded Documents:**
# ---------------------------------------
# 1. **One-to-Many Relationships with Unbounded Growth**:
#    - If the embedded array grows indefinitely, it can cause performance issues.
#    - Example: Storing all user orders inside a user document is inefficient for an e-commerce app.

# 2. **Data That is Accessed Independently**:
#    - If the embedded document is often queried separately, storing it in a separate collection improves efficiency.
#    - Example: Storing all customer service tickets inside a user document might not be ideal.

# **Conclusion:**
# - Embedded documents improve performance and simplify data retrieval when used correctly.
# - However, for large, frequently changing, or independently queried data, referencing with separate collections is better.

#Q16)  What is the purpose of MongoDB’s $lookup stage in aggregation?

# Ans)
# **MongoDB's `$lookup` Stage in Aggregation**
# -------------------------------------------
# - The `$lookup` stage in MongoDB's aggregation framework is used to perform
#   a LEFT OUTER JOIN between two collections.
# - It allows retrieving related documents from another collection and embedding
#   them into the output.

# **Purpose of `$lookup`:**
# -------------------------
# - To combine data from multiple collections in a single query.
# - To simulate relational JOIN operations in MongoDB.
# - To enhance query performance by reducing the number of separate queries.

# **Syntax of `$lookup`:**
# ------------------------
# {
#   $lookup: {
#     from: "other_collection",  # The collection to join with
#     localField: "field_in_main_collection",  # Field in the current collection
#     foreignField: "field_in_other_collection",  # Field in the other collection
#     as: "resulting_array"  # Name of the new field to store the joined documents
#   }
# }

# **Example Scenario:**
# ---------------------
# - Consider two collections: `orders` and `customers`.
# - We want to fetch customer details along with each order.

# **Orders Collection (`orders`):**
# { "_id": 1, "order_id": "A123", "customer_id": 101 }

# **Customers Collection (`customers`):**
# { "_id": 101, "name": "Arghyadeep", "email": "arghyadeep@example.com" }

# **Using `$lookup` to Join the Collections:**
'''aggregation_query = [
    {
        "$lookup": {
            "from": "customers",          # Collection to join
            "localField": "customer_id",  # Field in `orders`
            "foreignField": "_id",        # Matching field in `customers`
            "as": "customer_details"      # Output field
        }
    }
]'''

# **Expected Output:**
# {
#     "_id": 1,
#     "order_id": "A123",
#     "customer_id": 101,
#     "customer_details": [
#         { "_id": 101, "name": "Arghyadeep", "email": "arghyadeep@example.com" }
#     ]
# }

# **Key Points About `$lookup`:**
# --------------------------------
# - Returns an array of matched documents in the `as` field.
# - If no match is found, an empty array is returned.
# - Suitable for one-to-one and one-to-many relationships.
# - Can slow down queries if not indexed properly.

# **Conclusion:**
# - `$lookup` is a powerful tool for joining collections in MongoDB.
# - Best used when relationships between documents exist but are stored separately.
# - Proper indexing on `foreignField` improves query efficiency.

# Q17) What are some common use cases for MongoDB?

# Ans)
# **Common Use Cases for MongoDB**
# --------------------------------
# MongoDB is a NoSQL database that is widely used for handling large-scale,
# high-performance, and flexible data storage. Below are some common use cases:

# **1. Real-Time Analytics**
# --------------------------
# - MongoDB is used for storing and analyzing large volumes of real-time data.
# - Example: Financial transactions, stock market analysis, IoT sensor data.

# **2. Content Management Systems (CMS)**
# ---------------------------------------
# - MongoDB’s flexible schema is ideal for handling different types of content.
# - Example: Websites, blogs, news portals, and document storage.

# **3. Internet of Things (IoT)**
# -------------------------------
# - IoT devices generate vast amounts of unstructured data.
# - MongoDB efficiently stores and processes IoT data in real-time.
# - Example: Smart home systems, industrial automation, and connected devices.

# **4. E-Commerce Applications**
# ------------------------------
# - E-commerce platforms require fast, scalable, and flexible databases.
# - MongoDB handles product catalogs, customer data, and order tracking.
# - Example: Amazon, Flipkart, and Shopify-like platforms.

# **5. Gaming Applications**
# --------------------------
# - MongoDB manages real-time gaming data, leaderboards, and player profiles.
# - It supports dynamic game environments where data changes frequently.
# - Example: Online multiplayer games and mobile gaming apps.

# **6. Mobile and Web Applications**
# ----------------------------------
# - MongoDB provides fast data retrieval for mobile and web applications.
# - It supports offline data storage and synchronization.
# - Example: Social media apps, messaging platforms, and ride-sharing services.

# **7. Log Management and Monitoring**
# ------------------------------------
# - MongoDB is used for storing and analyzing logs from servers and applications.
# - Example: IT infrastructure monitoring, security event tracking.

# **8. Healthcare and Medical Records**
# -------------------------------------
# - Stores unstructured patient data, medical history, and clinical reports.
# - Example: Electronic Health Records (EHR), telemedicine platforms.

# **9. Fraud Detection and Cybersecurity**
# ----------------------------------------
# - MongoDB helps detect anomalies and fraud patterns in financial transactions.
# - Example: Banking, insurance, and cybersecurity monitoring.

# **10. Machine Learning and AI**
# -------------------------------
# - MongoDB is used to store training datasets for ML and AI applications.
# - It supports unstructured and semi-structured data formats.
# - Example: Image recognition, chatbots, recommendation systems.

# **Conclusion:**
# - MongoDB is a powerful NoSQL database suitable for diverse applications.
# - It provides scalability, flexibility, and high performance.
# - Ideal for handling unstructured, semi-structured, and real-time data.

# MongoDB is widely adopted across various industries, making it a go-to choice
# for modern applications that require high-speed data access and flexibility.

# Q18) What are the advantages of using MongoDB for horizontal scaling?

# Ans)
# **Advantages of Using MongoDB for Horizontal Scaling**
# ------------------------------------------------------
# Horizontal scaling (also known as sharding) in MongoDB allows databases to
# distribute data across multiple servers, improving performance and scalability.
# Below are the key advantages of using MongoDB for horizontal scaling:

# **1. High Availability**
# ------------------------
# - MongoDB distributes data across multiple nodes using sharding.
# - If one node fails, other nodes continue serving requests.
# - Ensures minimal downtime and continuous data availability.

# **2. Improved Performance**
# ---------------------------
# - Queries are distributed across multiple servers, reducing response time.
# - Load balancing ensures efficient resource utilization.
# - Ideal for handling large-scale applications with high user traffic.

# **3. Elastic Scalability**
# --------------------------
# - MongoDB allows adding more nodes to scale as data grows.
# - No need for downtime when expanding the database cluster.
# - Suitable for applications requiring rapid expansion.

# **4. Cost-Effective Solution**
# ------------------------------
# - Horizontal scaling is more cost-effective than vertical scaling.
# - Instead of upgrading a single powerful machine, multiple low-cost servers
#   can be used.
# - Reduces infrastructure costs for large-scale applications.

# **5. Automatic Data Distribution**
# ----------------------------------
# - MongoDB automatically distributes data across shards.
# - Ensures balanced data storage and efficient query execution.
# - No manual intervention is needed for data partitioning.

# **6. Better Read and Write Throughput**
# ---------------------------------------
# - Queries and writes can be distributed among multiple servers.
# - Improves database performance for read-heavy and write-heavy workloads.
# - Example: Social media platforms, real-time analytics, IoT applications.

# **7. Geographical Distribution**
# ---------------------------------
# - MongoDB’s sharding allows data to be distributed across different regions.
# - Enhances performance by serving users from geographically closer servers.
# - Reduces latency and improves user experience.

# **8. Fault Tolerance and Data Redundancy**
# ------------------------------------------
# - Replica sets in MongoDB ensure that multiple copies of data are available.
# - If one shard fails, another replica takes over to prevent data loss.
# - Increases database reliability and disaster recovery capability.

# **Conclusion:**
# - MongoDB’s horizontal scaling provides flexibility, high performance,
#   and cost efficiency.
# - Ideal for large-scale, data-intensive applications requiring real-time
#   processing and global distribution.
# - A preferred choice for modern cloud-based and distributed database systems.

# By leveraging MongoDB’s sharding capabilities, businesses can efficiently
# handle massive datasets while ensuring seamless performance and availability.

# Q19) How do MongoDB transactions differ from SQL transactions?

# Ans)
# **How MongoDB Transactions Differ from SQL Transactions**
# ---------------------------------------------------------
# Transactions ensure data consistency and integrity when performing multiple
# operations. Both MongoDB and SQL databases support transactions but differ
# in their implementation.

# **1. Multi-Document vs Multi-Row Transactions**
# -----------------------------------------------
# - **MongoDB:** Transactions operate on multiple documents within a single
#   or multiple collections.
# - **SQL Databases:** Transactions operate on multiple rows in multiple tables.

# **2. ACID Compliance**
# ----------------------
# - **MongoDB:** Starting from version 4.0, MongoDB supports ACID transactions,
#   but they are not as deeply integrated as in SQL databases.
# - **SQL Databases:** ACID properties (Atomicity, Consistency, Isolation,
#   Durability) are a fundamental part of SQL transactions.

# **3. Transaction Scope**
# ------------------------
# - **MongoDB:** Transactions are mainly used within a **replica set**.
#   In version 4.2+, they also work across sharded clusters.
# - **SQL Databases:** Transactions can span across multiple tables
#   and databases.

# **4. Performance Considerations**
# ---------------------------------
# - **MongoDB:** Transactions introduce additional overhead, as MongoDB is
#   designed for fast, schema-less document storage.
# - **SQL Databases:** Optimized for transactional consistency, but may
#   require complex joins and indexing.

# **5. Locking Mechanism**
# ------------------------
# - **MongoDB:** Uses **document-level locking**, meaning transactions
#   affect only specific documents.
# - **SQL Databases:** Uses **row-level, page-level, or table-level locking**,
#   which can impact performance.

# **6. Use Cases**
# ---------------
# - **MongoDB:** Best for applications where transactions are rare, but
#   flexibility and high-speed operations are required (e.g., e-commerce,
#   IoT, real-time analytics).
# - **SQL Databases:** Ideal for applications requiring frequent,
#   complex transactions with strict consistency (e.g., banking, financial systems).

# **Conclusion:**
# --------------
# - MongoDB provides transaction support but is optimized for high-performance,
#   distributed data storage.
# - SQL databases offer a more robust transaction model, making them
#   better suited for financial and enterprise applications.
# - Choosing between MongoDB and SQL depends on the **data structure,
#   consistency requirements, and scalability needs** of the application.

# Q20) What are the main differences between capped collections and regular collections?

# Ans)
# **Main Differences Between Capped Collections and Regular Collections**
# ----------------------------------------------------------------------
# MongoDB provides two types of collections: **Capped Collections** and **Regular Collections**.
# They differ in terms of storage behavior, performance, and use cases.

# **1. Fixed Size vs Dynamic Size**
# ---------------------------------
# - **Capped Collection:** Has a fixed maximum size (in bytes) or a fixed number of documents.
# - **Regular Collection:** Grows dynamically as new documents are inserted.

# **2. Auto-Deletion of Oldest Data**
# -----------------------------------
# - **Capped Collection:** Automatically removes the oldest documents when the size limit is reached.
# - **Regular Collection:** Does not delete old documents unless explicitly removed by the user.

# **3. Insertion Order Preservation**
# -----------------------------------
# - **Capped Collection:** Maintains the order of insertion and does not allow document deletion (except when dropping the collection).
# - **Regular Collection:** Does not guarantee insertion order and allows document deletion.

# **4. Performance Optimization**
# -------------------------------
# - **Capped Collection:** Offers faster writes as MongoDB pre-allocates space, making inserts very efficient.
# - **Regular Collection:** Slightly slower since storage is dynamically allocated.

# **5. Update Behavior**
# ----------------------
# - **Capped Collection:** Updates cannot change the document size, preventing fragmentation.
# - **Regular Collection:** Updates can modify document size, potentially causing fragmentation.

# **6. Indexing Support**
# -----------------------
# - **Capped Collection:** Supports only the `_id` index by default. Cannot create secondary indexes.
# - **Regular Collection:** Supports multiple indexes for optimized queries.

# **7. Use Cases**
# ---------------
# - **Capped Collection:** Ideal for real-time logging, caching, event monitoring, and sensor data.
# - **Regular Collection:** Best for general-purpose data storage where document retention is not size-restricted.

# **Conclusion:**
# --------------
# - Use **Capped Collections** for high-performance, real-time data that follows a First-In-First-Out (FIFO) pattern.
# - Use **Regular Collections** for general storage with flexible data retention policies.

# Q21)  What is the purpose of the $match stage in MongoDB’s aggregation pipeline?

# Ans)
# **Purpose of the $match Stage in MongoDB’s Aggregation Pipeline**
# ----------------------------------------------------------------
# The `$match` stage in MongoDB’s aggregation pipeline is used to filter documents
# based on specified conditions, similar to the `find()` query in MongoDB.

# **1. Primary Function**
# -----------------------
# - It selects documents that match a given condition before passing them to the next stage.
# - Helps reduce the number of documents processed in subsequent pipeline stages, improving performance.

# **2. Syntax Example**
# ---------------------
# { $match: { <field>: <value> } }
# - Filters documents where the field matches the given value.
# - Supports complex queries with comparison, logical, and array operators.

# **3. Performance Benefits**
# ---------------------------
# - Using `$match` early in the pipeline improves efficiency by reducing data volume.
# - It takes advantage of indexes if placed at the beginning of the pipeline.

# **4. Use Cases**
# ---------------
# - Extracting relevant data for reports and analysis.
# - Filtering documents before applying group, sort, or projection operations.
# - Improving aggregation performance by eliminating unnecessary documents early.

# **Example Query:**
# ------------------
# db.sales.aggregate([
#     { "$match": { "category": "Electronics", "price": { "$gt": 1000 } } },
#     { "$group": { "_id": "$category", "totalSales": { "$sum": "$price" } } }
# ])
# - The `$match` stage filters sales records where the category is "Electronics" and price > 1000.
# - The `$group` stage then calculates the total sales for the filtered documents.

# **Conclusion:**
# --------------
# - `$match` is essential for filtering documents efficiently in an aggregation pipeline.
# - Helps optimize queries by leveraging indexes and reducing the processing load.

# Q22)  How can you secure access to a MongoDB database?

# Ans)
# **How to Secure Access to a MongoDB Database**
# ----------------------------------------------
# MongoDB provides multiple security mechanisms to protect access to the database.

# **1. Enable Authentication**
# -----------------------------
# - By default, MongoDB allows connections without authentication.
# - To enforce authentication, create database users with roles and enable authentication in the configuration file.
# - Example command to create an admin user:
#   db.createUser({
#       user: "admin",
#       pwd: "securepassword",
#       roles: [ { role: "userAdminAnyDatabase", db: "admin" } ]
#   })
# - Then, start MongoDB with authentication enabled:
#   mongod --auth --port 27017 --dbpath /data/db

# **2. Use Role-Based Access Control (RBAC)**
# --------------------------------------------
# - Assign users only the permissions they need.
# - Built-in roles include `read`, `readWrite`, `dbAdmin`, and `clusterAdmin`.
# - Example: Grant read-write access to a user for a specific database:
#   db.createUser({
#       user: "appUser",
#       pwd: "strongpassword",
#       roles: [{ role: "readWrite", db: "appDB" }]
#   })

# **3. Enable TLS/SSL Encryption**
# ---------------------------------
# - Encrypts data in transit to prevent interception.
# - Configure MongoDB to use SSL/TLS certificates.
# - Start MongoDB with TLS enabled:
#   mongod --tlsMode requireTLS --tlsCertificateKeyFile /etc/ssl/mongodb.pem

# **4. Restrict Network Access**
# -------------------------------
# - Bind MongoDB to specific IP addresses to prevent unauthorized access.
# - Example (only allow localhost access):
#   mongod --bind_ip 127.0.0.1
# - In MongoDB Atlas, configure IP Whitelisting to allow only trusted IPs.

# **5. Enable Firewall Rules**
# -----------------------------
# - Use firewall settings (e.g., `iptables` or cloud security groups) to block unauthorized access.
# - Example (allow access only from a specific IP):
#   sudo iptables -A INPUT -p tcp --dport 27017 -s 192.168.1.100 -j ACCEPT

# **6. Encrypt Data at Rest**
# ----------------------------
# - Use MongoDB’s Encrypted Storage Engine to encrypt stored data.
# - Enable encryption with a key management system (KMS).

# **7. Disable Unnecessary Features**
# ------------------------------------
# - Disable HTTP Status Interface:
#   mongod --nohttpinterface
# - Disable REST API (if not needed):
#   mongod --rest false

# **8. Regularly Update MongoDB**
# --------------------------------
# - Keep MongoDB updated to protect against vulnerabilities.
# - Use long-term support (LTS) versions for stability.

# **Conclusion**
# -------------
# - Security best practices include authentication, encryption, network restrictions, and access control.
# - Regularly monitor and audit database activity to ensure security compliance.

# Q23) What is MongoDB’s WiredTiger storage engine, and why is it important?
# Ans)
# **MongoDB’s WiredTiger Storage Engine and Its Importance**
# -----------------------------------------------------------

# **1. Introduction to WiredTiger**
# ----------------------------------
# - WiredTiger is the default storage engine for MongoDB (since version 3.2).
# - It provides better performance, concurrency, and compression compared to the older MMAPv1 engine.

# **2. Key Features of WiredTiger**
# -----------------------------------
# - **Document-Level Concurrency Control**:
#   - Uses Multi-Version Concurrency Control (MVCC) to allow multiple read and write operations simultaneously.
#   - Reduces contention compared to collection-level locking in MMAPv1.
#
# - **Compression for Storage Efficiency**:
#   - Supports Snappy, Zlib, and Zstd compression for reducing disk space usage.
#   - Example: Snappy compression reduces storage cost while maintaining speed.
#
# - **Write-Ahead Logging (WAL)**:
#   - Uses a journal to ensure durability and crash recovery.
#   - Improves data integrity by logging changes before applying them.
#
# - **Checkpointing for Data Consistency**:
#   - Periodically writes checkpoints to disk for recovery in case of failure.
#   - Ensures faster recovery compared to full database rebuilds.
#
# - **Configurable Cache Management**:
#   - Uses an in-memory cache to improve query performance.
#   - Default cache size is 50% of available RAM but can be adjusted.
#   - Example (to set cache size to 2GB):
#     mongod --wiredTigerCacheSizeGB 2
#
# - **Support for Transactions**:
#   - Introduced in MongoDB 4.0, it enables ACID transactions for multi-document operations.
#   - Useful for financial applications and complex data consistency requirements.

# **3. Why is WiredTiger Important?**
# -------------------------------------
# - **Improves Write Performance**:
#   - Reduces lock contention, allowing high-throughput workloads.
#
# - **Efficient Storage Usage**:
#   - Compression reduces the cost of storage and enhances performance.
#
# - **Better Read and Write Concurrency**:
#   - Supports multiple readers and writers without blocking operations.
#
# - **Data Durability and Recovery**:
#   - WAL and checkpointing ensure data consistency even after crashes.
#
# - **Essential for Large-Scale Applications**:
#   - Ideal for handling massive datasets in real-time applications.

# **Conclusion**
# --------------
# - WiredTiger is a high-performance, modern storage engine in MongoDB.
# - It provides better concurrency, efficiency, and durability compared to MMAPv1.
# - It is crucial for applications requiring fast reads/writes, low storage costs, and strong data integrity.

# Practical Questions

!pip install "pymongo[srv]"

from pymongo.mongo_client import MongoClient
from pymongo.server_api import ServerApi

uri = "mongodb+srv://arghyadeepghosh7777:Arghyadeep%402002@cluster0.r5edq.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0"

# Create a new client and connect to the server
client = MongoClient(uri, server_api=ServerApi('1'))

# Send a ping to confirm a successful connection
try:
    client.admin.command('ping')
    print("Pinged your deployment. You successfully connected to MongoDB!")
except Exception as e:
    print(e)

import pandas as pd
df = pd.read_csv("superstore.csv", encoding="ISO-8859-1")
df.head()  # Display first few rows

# Q1)  Write a Python script to load the Superstore dataset from a CSV file into MongoDB

from pymongo import MongoClient

#  Select the database and collection
db = client["SuperstoreDB"]  # Creating/Selecting the database
collection = db["Orders"]  # Creating/Selecting the collection

#Convert DataFrame to a list of dictionaries (MongoDB format)
data = df.to_dict(orient="records")

# Insert data into MongoDB
collection.insert_many(data)

print("Data successfully loaded into MongoDB!")

# Output - Data successfully loaded into MongoDB!

# Q2)Retrieve and print all documents from the Orders collection.

# Retrieve and print all documents from the Orders collection
for doc in collection.find():
    print(doc)

# Q3) Count and display the total number of documents in the Orders collection.

# Count the total number of documents in the Orders collection
total_docs = collection.count_documents({})
print("Total number of documents in Orders collection:", total_docs)

# Q4) Write a query to fetch all orders from the "West" region.

# Query to fetch all orders from the "West" region
west_orders = collection.find({"Region": "West"})

# Display the fetched documents
for order in west_orders:
    print(order)

# Q5) Write a query to find orders where Sales is greater than 500

# Query to fetch orders where Sales > 500
high_sales_orders = collection.find({"Sales": {"$gt": 500}})

# Display the fetched documents
for order in high_sales_orders:
    print(order)

#Q6)  Fetch the top 3 orders with the highest Profit.

# Query to fetch the top 3 orders sorted by Profit in descending order
top_profit_orders = collection.find().sort("Profit", -1).limit(3)

# Display the fetched documents
for order in top_profit_orders:
    print(order)

'''
Output:

{'_id': ObjectId('67ad96ef085a4ce2580bbd58'), 'Row ID': 6827, 'Order ID': 'CA-2016-118689', 'Order Date': '10/2/2016', 'Ship Date': '10/9/2016', 'Ship Mode': 'Standard Class', 'Customer ID': 'TC-20980', 'Customer Name': 'Tamara Chand', 'Segment': 'Corporate', 'Country': 'United States', 'City': 'Lafayette', 'State': 'Indiana', 'Postal Code': 47905, 'Region': 'Central', 'Product ID': 'TEC-CO-10004722', 'Category': 'Technology', 'Sub-Category': 'Copiers', 'Product Name': 'Canon imageCLASS 2200 Advanced Copier', 'Sales': 17499.95, 'Quantity': 5, 'Discount': 0.0, 'Profit': 8399.976}
{'_id': ObjectId('67ad79dff3f322e9365e380f'), 'Row ID': 6827, 'Order ID': 'CA-2016-118689', 'Order Date': '10/2/2016', 'Ship Date': '10/9/2016', 'Ship Mode': 'Standard Class', 'Customer ID': 'TC-20980', 'Customer Name': 'Tamara Chand', 'Segment': 'Corporate', 'Country': 'United States', 'City': 'Lafayette', 'State': 'Indiana', 'Postal Code': 47905, 'Region': 'Central', 'Product ID': 'TEC-CO-10004722', 'Category': 'Technology', 'Sub-Category': 'Copiers', 'Product Name': 'Canon imageCLASS 2200 Advanced Copier', 'Sales': 17499.95, 'Quantity': 5, 'Discount': 0.0, 'Profit': 8399.976}
{'_id': ObjectId('67ad79dff3f322e9365e3d3e'), 'Row ID': 8154, 'Order ID': 'CA-2017-140151', 'Order Date': '3/23/2017', 'Ship Date': '3/25/2017', 'Ship Mode': 'Premium Class', 'Customer ID': 'RB-19360', 'Customer Name': 'Raymond Buch', 'Segment': 'Consumer', 'Country': 'United States', 'City': 'Seattle', 'State': 'Washington', 'Postal Code': 98115, 'Region': 'West', 'Product ID': 'TEC-CO-10004722', 'Category': 'Technology', 'Sub-Category': 'Copiers', 'Product Name': 'Canon imageCLASS 2200 Advanced Copier', 'Sales': 13999.96, 'Quantity': 4, 'Discount': 0.0, 'Profit': 6719.9808}
'''

# Q7) Update all orders with Ship Mode as "First Class" to "Premium Class".

# Update all documents where Ship Mode is "First Class" to "Premium Class"
collection.update_many(
    {"Ship Mode": "First Class"},  # Filter condition
    {"$set": {"Ship Mode": "Premium Class"}}  # Update operation
)

print("Update successful: All 'First Class' Ship Modes changed to 'Premium Class'.")

# Output - Update successful: All 'First Class' Ship Modes changed to 'Premium Class'.

# Q8)  Delete all orders where Sales is less than 50

 # Delete all documents where Sales is less than 50
result = collection.delete_many({"Sales": {"$lt": 50}})

# Print the number of deleted documents
print(f"Deleted {result.deleted_count} orders where Sales was less than 50.")

# Output - Deleted 4849 orders where Sales was less than 50.

# Q9) Use aggregation to group orders by Region and calculate total sales per region.

# Aggregation pipeline to group by Region and sum Sales
pipeline = [
    {"$group": {"_id": "$Region", "TotalSales": {"$sum": "$Sales"}}},
    {"$sort": {"TotalSales": -1}}  # Sorting in descending order of sales
]

# Execute aggregation
result = collection.aggregate(pipeline)

# Print the results
for doc in result:
    print(f"Region: {doc['_id']}, Total Sales: {doc['TotalSales']}")

'''Output
Region: West, Total Sales: 1389373.239
Region: East, Total Sales: 1302275.41
Region: Central, Total Sales: 959223.6916
Region: South, Total Sales: 752046.624
'''

# Q10)  Fetch all distinct values for Ship Mode from the collection.

# Fetch distinct Ship Mode values
distinct_ship_modes = collection.distinct("Ship Mode")

# Print the results
print(distinct_ship_modes)

# Output - ['Premium Class', 'Same Day', 'Second Class', 'Standard Class']

# Q11)  Count the number of orders for each category.

# Aggregation query to count orders per category
category_order_count = collection.aggregate([
    {"$group": {"_id": "$Category", "TotalOrders": {"$sum": 1}}}
])

# Print the results
for category in category_order_count:
    print(category)

''' Output:
{'_id': 'Furniture', 'TotalOrders': 3146}
{'_id': 'Technology', 'TotalOrders': 2992}
{'_id': 'Office Supplies', 'TotalOrders': 4152}
'''

